knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(cluster)
library(factoextra)
library(janitor)
library(lattice)
library(stats4)
library(flexclust)
setwd("C:/Users/Felipe/Documents/GitHub/Entregas_mineria_de_datos/Proyecto 2")
load(file="beats.RData")
summary(beats)
head(beats)
beats[,2:5] = NULL
beats[,3] = NULL
beats[,14:17] = NULL
beats[,15:17] = NULL
beats[,16:20] = NULL
beats[beats == ""] <- NA
beats %>%  summarise_all(funs(sum(is.na(.))))
data_semi_lista <- beats %>% filter(!(is.na(beats$album_release_year)))
data_semi_lista %>% summarise_all(funs(sum(is.na(.))))
data_lista <- data_semi_lista[!duplicated(data_semi_lista$track_name),]
data_lista = data_lista[1:1000]
data_lista = data_lista[1:1000,]
View(data_lista)
var_a_utilizar = data_lista[,3:13]
data_escalada=scale(var_a_utilizar) %>% as_tibble()
summary(data_escalada)
SSinterior <- numeric(25)
for(k in 1:25){
modelo <- kmeans(data_escalada, centers = k)
SSinterior[k] <- modelo$tot.withinss
}
plot(SSinterior)
modelo_kmeans <- kmeans(data_escalada, centers = 6)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(danceability,energy, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
#Estadistico de Hopkins
res <- get_clust_tendency(var_a_utilizar, n = 30, graph = FALSE)
print(res)
#Cohesion
cohesion = modelo_kmeans$tot.withinss
print(cohesion)
#Separation
meanData <- colMeans(data_escalada)
#Separation
meanData <- colMeans(as.numeric(data_escalada))
library(tidyverse)
library(cluster)
library(factoextra)
library(janitor)
library(lattice)
library(stats4)
library(flexclust)
setwd("C:/Users/Felipe/Documents/GitHub/Entregas_mineria_de_datos/Proyecto 2")
load(file="beats.RData")
summary(beats)
head(beats)
beats[,2:5] = NULL
beats[,3] = NULL
beats[,14:17] = NULL
beats[,15:17] = NULL
beats[,16:20] = NULL
beats[beats == ""] <- NA
beats %>%  summarise_all(funs(sum(is.na(.))))
data_semi_lista <- beats %>% filter(!(is.na(beats$album_release_year)))
data_semi_lista %>% summarise_all(funs(sum(is.na(.))))
data_lista <- data_semi_lista[!duplicated(data_semi_lista$track_name),]
data_lista = data_lista[1:1000,]
var_a_utilizar = data_lista[,3:13]
data_escalada=scale(var_a_utilizar) %>% as_tibble()
summary(data_escalada)
SSinterior <- numeric(25)
for(k in 1:25){
modelo <- kmeans(data_escalada, centers = k)
SSinterior[k] <- modelo$tot.withinss
}
plot(SSinterior)
coefSil=numeric(20)
for (k in 2:20){
modelo <- kmeans(data_escalada, centers = k)
temp <- silhouette(modelo$cluster,dist(data_escalada))
coefSil[k] <- mean(temp[,3])
}
tempDF=data.frame(CS=coefSil,K=c(1:30))
coefSil=numeric(20)
for (k in 2:20){
modelo <- kmeans(data_escalada, centers = k)
temp <- silhouette(modelo$cluster,dist(data_escalada))
coefSil[k] <- mean(temp[,3])
}
tempDF=data.frame(CS=coefSil,K=c(1:30))
coefSil=numeric(20)
for (k in 2:20){
modelo <- kmeans(data_escalada, centers = k)
temp <- silhouette(modelo$cluster,dist(data_escalada))
coefSil[k] <- mean(temp[,3])
}
tempDF=data.frame(CS=coefSil,K=c(1:20))
ggplot(tempDF, aes(x=K, y=CS)) + geom_line() + scale_x_continuous(breaks=c(1:30))
SSinterior <- numeric(25)
for(k in 1:25){
modelo <- kmeans(data_escalada, centers = k)
SSinterior[k] <- modelo$tot.withinss
}
plot(SSinterior)
coefSil=numeric(20)
for (k in 2:20){
modelo <- kmeans(data_escalada, centers = k)
temp <- silhouette(modelo$cluster,dist(data_escalada))
coefSil[k] <- mean(temp[,3])
}
tempDF=data.frame(CS=coefSil,K=c(1:20))
ggplot(tempDF, aes(x=K, y=CS)) + geom_line() + scale_x_continuous(breaks=c(1:30))
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(danceability,energy, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(energy,danceability color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(energy,danceability, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(energy,key, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(energy,loudness, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(danceability,loudness, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(energy,loudness, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
SSinterior <- numeric(30)
for(k in 1:30){
modelo <- kmeans(data_escalada, centers = k)
SSinterior[k] <- modelo$tot.withinss
}
plot(SSinterior)
modelo_kmeans <- kmeans(data_escalada, centers = 3)
data_escalada$clus <- modelo_kmeans$cluster %>% as.factor()
ggplot(data_escalada, aes(energy,loudness, color=clus)) +  geom_point(alpha=0.5, show.legend = F) +  theme_bw()
res <- get_clust_tendency(var_a_utilizar, n = 30, graph = FALSE)
print(res)
res <- get_clust_tendency(var_a_utilizar, n = 10, graph = FALSE)
print(res)
res <- get_clust_tendency(var_a_utilizar, n = 20, graph = FALSE)
print(res)
tempMatrix <- matrix(0, nrow = nrow(data_escalada), ncol = nrow(data_escalada))
tempMatrix[which(index$x==1), which(index$x==1)]  <- 1
View(data_escalada)
#################
data_escalada <- apply(data_escalada,2,as.numeric)
#Cohesion
withinCluster <- numeric(10)
#Cohesion
withinCluster <- numeric(3)   #AQUI VA EL VALOR DE LA CANTIDAD DE CLUSTERS DETERMINADO
for (i in 1:3){               #AQUI VA EL VALOR DE LA CANTIDAD DE CLUSTERS DETERMINADO PORQUE ES "PARA CADA CLUSTER" EL FOR
tempData <- data_escalaDA[which(modelo_kmeans$cluster == i),]
withinCluster[i] <- sum(dist2(tempData,colMeans(tempData))^2)
}
for (i in 1:3){               #AQUI VA EL VALOR DE LA CANTIDAD DE CLUSTERS DETERMINADO PORQUE ES "PARA CADA CLUSTER" EL FOR
tempData <- data_escalada[which(modelo_kmeans$cluster == i),]
withinCluster[i] <- sum(dist2(tempData,colMeans(tempData))^2)
}
cohesion = sum(withinCluster)
#es equivalente a model$tot.withinss en k-means
print(c(cohesion, modelo_kmeans$tot.withinss))
print(modelo_kmeans$tot.withinss)
meanData <- colMeans(data_escalada)
SSB <- numeric(3)
for (i in 1:3){
tempData <- data_escalada[which(modelo_kmeans$cluster==i),]
SSB[i] <- nrow(tempData)*sum((meanData-colMeans(tempData))^2)
}
separation = sum(SSB)
print(separation)
coefSil <- silhouette(modelo_kmeans$cluster,dist(data_escalada))
summary(coefSil)
#visualizamos el codigo de silueta de cada cluster
fviz_silhouette(coefSil) + coord_flip()
lista_kmeans= list(data_escalada$clus == 1)
View(data_escalada)
data_escalada_kmeans=as.data.frame(data_escalada)
lista_kmeans= list(data_escalada_kmeans$clus == 1)
print(lista_kmeans)
View(data_escalada_kmeans)
#Distancia euclideana
distancia_Jerarquicos = dist(data_escalada)
hist(distancia_Jerarquicos)
#Distancia euclideana
distancia_Jerarquicos = dist(data_escalada)
hist(distancia_Jerarquicos)
modelo_jerarquico = hclust(distancia_Jerarquicos, method="complete")
summary(modelo_jerarquico)
library(tidyverse)
library(cluster)
library(factoextra)
library(janitor)
library(lattice)
library(stats4)
library(flexclust)
library("ggdendro")
ggdendrogram(modelo_jerarquico, rotate = TRUE, theme_dendro = TRUE)
groups <- cutree(modelo_jerarquico, h = 5)
coefsil <- silhouette(groups, distancia_Jerarquicos)
groups %>% unique() %>% length()
summary(coefsil)
groups <- cutree(modelo_jerarquico, h = 6)
coefsil <- silhouette(groups, distancia_Jerarquicos)
groups %>% unique() %>% length()
summary(coefsil)
res <- tibble("h" = quantile(d, probs  = (1:100)/100), n = 0)
res <- tibble("h" = quantile(distancia_Jerarquicos, probs  = (1:100)/100), n = 0)
for (i in 1:100){
groups <- cutree(model_average, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
res <- tibble("h" = quantile(distancia_Jerarquicos, probs  = (1:100)/100), n = 0)
for (i in 1:100){
groups <- cutree(modelo_jerarquico, h = res$h[i])
res$n[i] <- groups %>% unique() %>% length()
}
ggplot(res, aes(h, n)) + geom_point() +  scale_x_log10() +  scale_y_log10()
